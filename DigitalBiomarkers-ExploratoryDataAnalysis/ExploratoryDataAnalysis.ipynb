{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis \n",
    "\n",
    "This file is composed of components of the EDA process for preliminary exploration of your data. This code is not a complete EDA, but rather a preliminary examination of data. Please see the Table of Contents to explore different areas of EDA.\n",
    "***\n",
    "\n",
    "##### **Input:** .csv file with entire dataset. Will need to interpolate prior to using unsupervised learning if NaN exist in your dataset\n",
    "##### **Output:** Figures for EDA\n",
    "##### **Dependencies:** \n",
    "***\n",
    "\n",
    "##### Format of input: \n",
    ".csv file with entire dataset \n",
    "***\n",
    "\n",
    "**Check:** \n",
    "* Will need to interpolate data/remove NaN before doing any unsupervised learning for EDA\n",
    "\n",
    "**Sources:**\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### Exploratory Data Analysis\n",
    "* [Cleaning and Filtering Data](#read)\n",
    "* [Correlation Plots](#corr)\n",
    "* [Covariance Matrix](#cov)\n",
    "* [Missing Data Analysis](#miss)\n",
    "* [Outlier Analysis](#out)\n",
    "* [Histograms of Features](#hist)\n",
    "\n",
    "#### Unsupervised Learning\n",
    "* [Clustering](#cluster)\n",
    "    * [KNN Clustering](#knn)\n",
    "    * [Hierarchical Clustering](#hic)\n",
    "* [Principal Component Analysis (PCA)](#pca)\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data:\n",
    "<a id=\"read\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(filename)  #Change filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Exploratory Data Analysis:\n",
    "\n",
    "https://github.com/dformoso/sklearn-classification/blob/master/Data%20Science%20Workbook%20-%20Census%20Income%20Dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plots\n",
    "<a id=\"corr\" ></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Plot\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Matrix\n",
    "<a id=\"cov\"></a>\n",
    "\n",
    "Compute pairwise covariance of columns\n",
    "\n",
    "Covariance is a measure of how much two random variables vary together. Itâ€™s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\n",
    "*Covariance must be scaled.*\n",
    "\n",
    "- Python: https://www.geeksforgeeks.org/python-pandas-dataframe-cov/\n",
    "- Math/Interpretation: https://www.statisticshowto.datasciencecentral.com/covariance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Need to standardize scale:\n",
    "cv_df = data.drop(columns=[]) #drop all columns that are non-numeric\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "cv_np = sc.fit_transform(cv_df)\n",
    "cv_df = pd.DataFrame(cv_np)\n",
    "#cv_df.columns = [] #name columns if desired\n",
    "\n",
    "#covariance \n",
    "cv_df.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values\n",
    "<a id=\"miss\"></a>\n",
    "#### Very cool package for missing values (includes heatmaps of missing, bar graphs, and matrices of missing values):\n",
    "https://github.com/ResidentMario/missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "#Check for missing data\n",
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Distribution of Each Feature\n",
    "<a id=\"dist\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome variable \n",
    "\n",
    "To look at how the outcome variable is balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(20,1)) \n",
    "sns.countplot(y=outcomevariablehere, data=data); #put outcomevariable here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distributions by outcome class \n",
    "<a id=\"dist-class\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sort dataframe by outcome\n",
    "\n",
    "#Plot outcome variables\n",
    "sns.distplot(outcome_a[[X1]], hist=False, rug=True)\n",
    "sns.distplot(outcome_b[[X1]], hist=False, rug=True)\n",
    "sns.distplot(outcome_c[[X1]], hist=False, rug=True)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.legend(labels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all variables at once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis\n",
    "<a id=\"out\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=variablehere, x=variablehere, data=data, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms of all variables in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makehist(datainput, label, color):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    mean = datainput.mean(axis = 0) #changeoutcomevar\n",
    "    plt.hist(datainput, bins=(20), align='mid', color=color, alpha=0.5)\n",
    "    plt.axvline(x=mean, color=color, linestyle='-')\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title((label + ' Histogram'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig((filesource + label + '.png'), dpi=100) #change filesource or add as input to function if variable\n",
    "    print(('Saved plot of ' + label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makehist(data['Variable'], 'Variable', 'green')\n",
    "#Repeat above command for each numeric Variable in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Section- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "<a id=\"cluster\"></a>\n",
    "\n",
    "https://www.neuroelectrics.com/blog/clustering-methods-in-exploratory-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = data.drop(columns=[]) # drop all non-numeric columns\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Clustering:\n",
    "<a id=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# create kmeans object\n",
    "kmeans = KMeans(n_clusters=3)# fit kmeans object to data\n",
    "kmeans.fit(dfc)# print location of clusters learned by kmeans object\n",
    "#print(kmeans.cluster_centers_)# save new clusters for chart\n",
    "y_km = kmeans.fit_predict(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "dfc['clusters'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "<a id=\"hic\"></a>\n",
    "\n",
    "*Agglomerative (data points are clustered using a bottim-up approach starting with individual data points)\n",
    "\n",
    "\n",
    "https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Data Dendograms\")\n",
    "dend = shc.dendrogram(shc.linkage(dfc, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (Prinicipal Component Analysis)\n",
    "<a id=\"pca\"></a>\n",
    "https://cmdlinetips.com/2018/03/pca-example-in-python-with-scikit-learn/\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html\n",
    "\n",
    "PCA selects the successive components that explain the maximum variance in the signal.\n",
    "This is useful to us because we have a large amount of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to scale prior to doing PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sdfc = sc.fit_transform(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(sdfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 9\n",
    "pc = pca.fit(dfc)\n",
    "\n",
    "result=pd.DataFrame(pca.transform(dfc), columns=['PCA%i' % i for i in range(9)], index=dfc.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcft = pca.fit_transform(dfc)\n",
    "\n",
    "pc_df = pd.DataFrame(data=pcft, columns= ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9'])\n",
    "\n",
    "#Example below:\n",
    "#pc_df['Cluster'] = data['Definition']\n",
    "#pc_df['Status'] = data['Status']\n",
    "#pc_df['Gender'] = data['Gender']\n",
    "pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "dfvar = pd.DataFrame({'var':pca.explained_variance_ratio_,\n",
    "             'PC':['PC1','PC2','PC3','PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9']})\n",
    "sns.barplot(x='PC',y=\"var\", \n",
    "           data=dfvar, color=\"c\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install matplotlib widget Ipython magic: https://github.com/matplotlib/jupyter-matplotlib\n",
    "\n",
    "Problems with matplotlib widget not working: https://github.com/matplotlib/jupyter-matplotlib/issues/66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "\n",
    "\n",
    "pc_df[insertvarhere]=pd.Categorical(pc_df[insertvarhere]) #need to change insertvarhere\n",
    "my_color=pc_df[insertvarhere].cat.codes                   #need to change insertvarhere\n",
    "\n",
    "# Plot initialisation\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig) \n",
    "ax.scatter(result['PCA0'], result['PCA1'], result['PCA2'], c=my_color, cmap='Accent', s=60)\n",
    "\n",
    "#make simple, bare axis lines through space:\n",
    "xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))\n",
    "ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))\n",
    "ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))\n",
    "ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    " \n",
    "# label the axes\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "ax.set_title(\"PCA\")\n",
    "#ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot( x=\"PC1\", y=\"PC5\",\n",
    "  data=pc_df, \n",
    "  fit_reg=False, \n",
    "  hue=Variable, # color by change variable here\n",
    "  legend=True,\n",
    "  scatter_kws={\"s\": 80,'alpha':0.3}) # specify the point size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
