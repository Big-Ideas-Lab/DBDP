{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('plain_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.reindex(columns = ['ACC1', 'ACC2', 'ACC3', 'TEMP', 'EDA', 'BVP', 'HR', 'Magnitude', 'Subject_ID', 'Round', 'Activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC1</th>\n",
       "      <th>ACC2</th>\n",
       "      <th>ACC3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EDA</th>\n",
       "      <th>BVP</th>\n",
       "      <th>HR</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Round</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.275354</td>\n",
       "      <td>15.25</td>\n",
       "      <td>78.980</td>\n",
       "      <td>63.410094</td>\n",
       "      <td>19-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>-12.75</td>\n",
       "      <td>78.835</td>\n",
       "      <td>63.453054</td>\n",
       "      <td>19-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.270231</td>\n",
       "      <td>-42.99</td>\n",
       "      <td>78.690</td>\n",
       "      <td>63.496142</td>\n",
       "      <td>19-001</td>\n",
       "      <td>1</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC1  ACC2  ACC3   TEMP       EDA    BVP      HR  Magnitude Subject_ID  \\\n",
       "0  41.0  27.2  40.0  32.39  0.275354  15.25  78.980  63.410094     19-001   \n",
       "1  41.0  27.3  40.0  32.39  0.276634 -12.75  78.835  63.453054     19-001   \n",
       "2  41.0  27.4  40.0  32.39  0.270231 -42.99  78.690  63.496142     19-001   \n",
       "\n",
       "   Round  Activity  \n",
       "0      1  Baseline  \n",
       "1      1  Baseline  \n",
       "2      1  Baseline  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode Activity and Subject_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the y variable as we need to one-hot encode this y variable for the model. The label each class is associated with is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Activity': 0, 'Baseline': 1, 'DB': 2, 'Type': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Activity'] = le.fit_transform(df['Activity'])\n",
    "\n",
    "activity_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(activity_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "df['Subject_ID'] = le1.fit_transform(df['Subject_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and train sets (by Subject ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = list(df['Subject_ID'].unique())\n",
    "random.shuffle(ID_list)\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229680, 11) (50160, 11)\n"
     ]
    }
   ],
   "source": [
    "train = df[df['Subject_ID'].isin(ID_list[:45])]\n",
    "test = df[df['Subject_ID'].isin(ID_list[45:])]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the test train split can be changed by changing the index below. For our purposes, n = 44 for train and n = 11 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229680, 9) (229680,) (50160, 9) (50160,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:,0:9]\n",
    "X_test = test.iloc[:,0:9]\n",
    "\n",
    "y_train = train.iloc[:,-1].values\n",
    "y_test = test.iloc[:,-1].values\n",
    "\n",
    "print(X_train.shape,  y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create X_train_df below so that we are able to use the Subject_ID column later on, to iterate through our leave one group out validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply one-hot encoding to Subject ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding is applied so subject_ID, so that it may be used as a variable in our model. This allows the model to understand that testing data contains new subjects that are not present in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['train'] =1\n",
    "X_test['train'] = 0\n",
    "\n",
    "combined = pd.concat([X_train, X_test])\n",
    "combined = pd.concat([combined, pd.get_dummies(combined['Subject_ID'])], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229680, 63) (50160, 63) 279840\n"
     ]
    }
   ],
   "source": [
    "X_train = combined[combined['train'] == 1]\n",
    "X_test = combined[combined['train'] == 0]\n",
    "\n",
    "X_train.drop([\"train\", \"Subject_ID\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"train\", \"Subject_ID\"], axis = 1, inplace = True)\n",
    "print(X_train.shape, X_test.shape, X_train.shape[0] + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the y variable as we need to one-hot encode this y variable for the model. Tensorflow requires one-hot encoding for more than two classes in the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dummy = np_utils.to_categorical(y_train)\n",
    "y_test_dummy = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale/normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is used to change values without distorting differences in the range of values for each sensor. We do this because different sensor values are not in similar ranges of each other and if we did not scale the data, gradients may oscillate back and forth and take a long time before finding the local minimum. It may not be necessary for this data, but to be sure, we normalized the features.\n",
    "\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "$$z = \\frac{x-u}{s}$$\n",
    "\n",
    "Where u is the mean of the data, and s is the standard deviation of the data of a single sample. The scaling is fit on the training set and applied to both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train.iloc[:,:8] = ss.fit_transform(X_train.iloc[:,:8])\n",
    "X_test.iloc[:,:8] = ss.transform(X_test.iloc[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 hidden **fully connected** layers with 32 nodes\n",
    "\n",
    "- The **Dropout** layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "\n",
    "- **Softmax** acitvation function - Used to generate probabilities for each class as an output in the final fully connected layer of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use ADAM as our optimizer as it is computationally efficient and updates the learning rate on a per-parameter basis, based on a moving estimate per-parameter gradient, and the per-parameter squared gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 912us/step - loss: 0.5781 - accuracy: 0.7777\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 6s 912us/step - loss: 0.4409 - accuracy: 0.8389\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 909us/step - loss: 0.4106 - accuracy: 0.8509\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 880us/step - loss: 0.3975 - accuracy: 0.8572\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 867us/step - loss: 0.3880 - accuracy: 0.8603\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 873us/step - loss: 0.3825 - accuracy: 0.8616\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 861us/step - loss: 0.3763 - accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 862us/step - loss: 0.3714 - accuracy: 0.8653\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 860us/step - loss: 0.3684 - accuracy: 0.8667\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 863us/step - loss: 0.3665 - accuracy: 0.8670\n",
      "Score for fold 1: loss of 0.8199766874313354; accuracy of 68.21969747543335%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 866us/step - loss: 0.5807 - accuracy: 0.7735\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 6s 900us/step - loss: 0.4404 - accuracy: 0.8346\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 897us/step - loss: 0.4116 - accuracy: 0.8464\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 949us/step - loss: 0.3967 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 953us/step - loss: 0.3850 - accuracy: 0.8556\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3743 - accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 900us/step - loss: 0.3681 - accuracy: 0.8616\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3632 - accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3585 - accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3519 - accuracy: 0.8707\n",
      "Score for fold 2: loss of 3.07902455329895; accuracy of 41.912877559661865%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 927us/step - loss: 0.5785 - accuracy: 0.7755\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4382 - accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 947us/step - loss: 0.4053 - accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 857us/step - loss: 0.3897 - accuracy: 0.8565\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 823us/step - loss: 0.3804 - accuracy: 0.8599\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 867us/step - loss: 0.3727 - accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 865us/step - loss: 0.3693 - accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 869us/step - loss: 0.3645 - accuracy: 0.8662\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 855us/step - loss: 0.3594 - accuracy: 0.8679\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 831us/step - loss: 0.3588 - accuracy: 0.8675\n",
      "Score for fold 3: loss of 1.0879307985305786; accuracy of 69.26136612892151%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 919us/step - loss: 0.5738 - accuracy: 0.7807\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4372 - accuracy: 0.8385\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 940us/step - loss: 0.4060 - accuracy: 0.8498\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 850us/step - loss: 0.3918 - accuracy: 0.8556\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 819us/step - loss: 0.3825 - accuracy: 0.8593\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 874us/step - loss: 0.3727 - accuracy: 0.8626\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 959us/step - loss: 0.3663 - accuracy: 0.8648\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 917us/step - loss: 0.3600 - accuracy: 0.8668\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 963us/step - loss: 0.3558 - accuracy: 0.8681\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 996us/step - loss: 0.3523 - accuracy: 0.8698\n",
      "Score for fold 4: loss of 1.278082251548767; accuracy of 55.71969747543335%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5710 - accuracy: 0.7790\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 954us/step - loss: 0.4321 - accuracy: 0.8386\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 925us/step - loss: 0.4013 - accuracy: 0.8504\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 951us/step - loss: 0.3866 - accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3778 - accuracy: 0.8602\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3695 - accuracy: 0.8629\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3653 - accuracy: 0.8630\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3607 - accuracy: 0.8655\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3547 - accuracy: 0.8682\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3510 - accuracy: 0.8697\n",
      "Score for fold 5: loss of 1.2896097898483276; accuracy of 55.75757622718811%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5830 - accuracy: 0.7727\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.4450 - accuracy: 0.8346\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4148 - accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 917us/step - loss: 0.3971 - accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 894us/step - loss: 0.3862 - accuracy: 0.8584\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3781 - accuracy: 0.8601\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3742 - accuracy: 0.8618\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 973us/step - loss: 0.3699 - accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 897us/step - loss: 0.3670 - accuracy: 0.8645\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 894us/step - loss: 0.3649 - accuracy: 0.8650\n",
      "Score for fold 6: loss of 1.4960379600524902; accuracy of 55.30303120613098%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 901us/step - loss: 0.5759 - accuracy: 0.7796\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4416 - accuracy: 0.8390\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4122 - accuracy: 0.8505\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 810us/step - loss: 0.3935 - accuracy: 0.8563\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 823us/step - loss: 0.3833 - accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3780 - accuracy: 0.8619\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3729 - accuracy: 0.8623\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3693 - accuracy: 0.8648\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 6s 923us/step - loss: 0.3661 - accuracy: 0.8649\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 989us/step - loss: 0.3641 - accuracy: 0.8661\n",
      "Score for fold 7: loss of 0.5899096131324768; accuracy of 74.73484873771667%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 992us/step - loss: 0.5718 - accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 6s 909us/step - loss: 0.4273 - accuracy: 0.8455\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 887us/step - loss: 0.3961 - accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3803 - accuracy: 0.8628\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3719 - accuracy: 0.8660\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3645 - accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 988us/step - loss: 0.3615 - accuracy: 0.8691\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 956us/step - loss: 0.3557 - accuracy: 0.8709\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3526 - accuracy: 0.8719\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3495 - accuracy: 0.8736\n",
      "Score for fold 8: loss of 1.363754153251648; accuracy of 50.43560862541199%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5796 - accuracy: 0.7760\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 966us/step - loss: 0.4438 - accuracy: 0.8399\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 997us/step - loss: 0.4122 - accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 999us/step - loss: 0.3995 - accuracy: 0.8563\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3878 - accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 13s 2ms/step - loss: 0.3812 - accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3756 - accuracy: 0.8634\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3716 - accuracy: 0.8652\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3656 - accuracy: 0.8672\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 937us/step - loss: 0.3652 - accuracy: 0.8674\n",
      "Score for fold 9: loss of 0.6297767162322998; accuracy of 82.15909004211426%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 875us/step - loss: 0.5778 - accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 6s 868us/step - loss: 0.4360 - accuracy: 0.8399\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 818us/step - loss: 0.4034 - accuracy: 0.85100s\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3867 - accuracy: 0.8567\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 912us/step - loss: 0.3784 - accuracy: 0.8593\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 910us/step - loss: 0.3697 - accuracy: 0.8622\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3674 - accuracy: 0.8632\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3624 - accuracy: 0.8656\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3600 - accuracy: 0.8664\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 916us/step - loss: 0.3566 - accuracy: 0.8674\n",
      "Score for fold 10: loss of 5.357129096984863; accuracy of 19.33712065219879%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 11 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5703 - accuracy: 0.7772\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 975us/step - loss: 0.4382 - accuracy: 0.8364\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 949us/step - loss: 0.4090 - accuracy: 0.8484\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 993us/step - loss: 0.3925 - accuracy: 0.8553\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3808 - accuracy: 0.8596: 0s - loss: 0.3814 - \n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 945us/step - loss: 0.3713 - accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 827us/step - loss: 0.3679 - accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8673\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3564 - accuracy: 0.8684\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 857us/step - loss: 0.3532 - accuracy: 0.8697\n",
      "Score for fold 11: loss of 8.96064567565918; accuracy of 13.428030908107758%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 12 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 958us/step - loss: 0.5768 - accuracy: 0.7780\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 12s 2ms/step - loss: 0.4420 - accuracy: 0.8362\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 948us/step - loss: 0.4060 - accuracy: 0.8483\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 819us/step - loss: 0.3909 - accuracy: 0.8533\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 850us/step - loss: 0.3789 - accuracy: 0.8581\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 869us/step - loss: 0.3698 - accuracy: 0.8615\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 905us/step - loss: 0.3631 - accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 880us/step - loss: 0.3568 - accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 854us/step - loss: 0.3559 - accuracy: 0.8672\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 862us/step - loss: 0.3511 - accuracy: 0.8682\n",
      "Score for fold 12: loss of 1.4444950819015503; accuracy of 61.6287887096405%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 13 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 946us/step - loss: 0.5800 - accuracy: 0.77180s - loss: 0.5803 - accuracy: 0.77\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 976us/step - loss: 0.4396 - accuracy: 0.8363\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4090 - accuracy: 0.8487\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3951 - accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 983us/step - loss: 0.3852 - accuracy: 0.8570\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 948us/step - loss: 0.3795 - accuracy: 0.8577\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 975us/step - loss: 0.3713 - accuracy: 0.8606\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3668 - accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3602 - accuracy: 0.8658\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3595 - accuracy: 0.8648\n",
      "Score for fold 13: loss of 1.038083791732788; accuracy of 70.37878632545471%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 14 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5638 - accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4304 - accuracy: 0.8431\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 925us/step - loss: 0.3991 - accuracy: 0.8550\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 892us/step - loss: 0.3842 - accuracy: 0.8597\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 953us/step - loss: 0.3761 - accuracy: 0.8625\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 7s 951us/step - loss: 0.3705 - accuracy: 0.8649\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 964us/step - loss: 0.3647 - accuracy: 0.8666\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 907us/step - loss: 0.3605 - accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 905us/step - loss: 0.3550 - accuracy: 0.8715\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 936us/step - loss: 0.3535 - accuracy: 0.8716\n",
      "Score for fold 14: loss of 1.5127209424972534; accuracy of 47.121211886405945%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 15 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 956us/step - loss: 0.5874 - accuracy: 0.7721\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 952us/step - loss: 0.4454 - accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 989us/step - loss: 0.4138 - accuracy: 0.8465\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3980 - accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3863 - accuracy: 0.8576\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3774 - accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3721 - accuracy: 0.8624\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 965us/step - loss: 0.3662 - accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 955us/step - loss: 0.3602 - accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3554 - accuracy: 0.8683\n",
      "Score for fold 15: loss of 0.6717286109924316; accuracy of 67.91666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 16 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5788 - accuracy: 0.7763\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4460 - accuracy: 0.8359\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 993us/step - loss: 0.4112 - accuracy: 0.8478\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 997us/step - loss: 0.3959 - accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 927us/step - loss: 0.3833 - accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 6s 808us/step - loss: 0.3756 - accuracy: 0.8616\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 807us/step - loss: 0.3712 - accuracy: 0.8637\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 788us/step - loss: 0.3665 - accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 6s 811us/step - loss: 0.3603 - accuracy: 0.8671\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 805us/step - loss: 0.3574 - accuracy: 0.8677\n",
      "Score for fold 16: loss of 5.605130195617676; accuracy of 18.106061220169067%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 17 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 6s 789us/step - loss: 0.5799 - accuracy: 0.7740\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 6s 806us/step - loss: 0.4447 - accuracy: 0.8347\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 6s 799us/step - loss: 0.4134 - accuracy: 0.8465\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 6s 871us/step - loss: 0.3968 - accuracy: 0.8517\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 6s 816us/step - loss: 0.3878 - accuracy: 0.8551\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 5s 779us/step - loss: 0.3790 - accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 818us/step - loss: 0.3741 - accuracy: 0.8604\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 6s 826us/step - loss: 0.3694 - accuracy: 0.8633\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 5s 784us/step - loss: 0.3658 - accuracy: 0.8631\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 6s 795us/step - loss: 0.3623 - accuracy: 0.8643\n",
      "Score for fold 17: loss of 0.4586189389228821; accuracy of 64.05302882194519%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 18 ...\n",
      "Epoch 1/10\n",
      "7095/7095 [==============================] - 5s 758us/step - loss: 0.5895 - accuracy: 0.7708\n",
      "Epoch 2/10\n",
      "7095/7095 [==============================] - 9s 1ms/step - loss: 0.4456 - accuracy: 0.8339\n",
      "Epoch 3/10\n",
      "7095/7095 [==============================] - 21s 3ms/step - loss: 0.4143 - accuracy: 0.8439\n",
      "Epoch 4/10\n",
      "7095/7095 [==============================] - 11s 2ms/step - loss: 0.3956 - accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "7095/7095 [==============================] - 10s 1ms/step - loss: 0.3834 - accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "7095/7095 [==============================] - 10s 1ms/step - loss: 0.3762 - accuracy: 0.8591\n",
      "Epoch 7/10\n",
      "7095/7095 [==============================] - 8s 1ms/step - loss: 0.3725 - accuracy: 0.8603\n",
      "Epoch 8/10\n",
      "7095/7095 [==============================] - 6s 833us/step - loss: 0.3672 - accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "7095/7095 [==============================] - 7s 1ms/step - loss: 0.3648 - accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "7095/7095 [==============================] - 7s 1ms/step - loss: 0.3628 - accuracy: 0.8643\n",
      "Score for fold 18: loss of 1.9721722602844238; accuracy of 27.007576823234558%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 19 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5755 - accuracy: 0.7797\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4380 - accuracy: 0.8387\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4101 - accuracy: 0.8491\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3958 - accuracy: 0.8543\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3862 - accuracy: 0.8577\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3778 - accuracy: 0.8605\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3721 - accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3706 - accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3682 - accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3660 - accuracy: 0.8649\n",
      "Score for fold 19: loss of 0.6462146639823914; accuracy of 80.07575869560242%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 20 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 986us/step - loss: 0.5824 - accuracy: 0.7730\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 947us/step - loss: 0.4395 - accuracy: 0.8379\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4113 - accuracy: 0.8479: 0s - loss: 0.4\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3964 - accuracy: 0.8545 0s - loss: 0.3967 - accura - ETA: 0s - loss: 0\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3857 - accuracy: 0.8591\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3776 - accuracy: 0.8624\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3732 - accuracy: 0.8634\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3682 - accuracy: 0.8652\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3634 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3604 - accuracy: 0.8688 \n",
      "Score for fold 20: loss of 0.8612075448036194; accuracy of 70.01894116401672%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 21 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.5787 - accuracy: 0.7758\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.4459 - accuracy: 0.8351\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 12s 2ms/step - loss: 0.4162 - accuracy: 0.8464\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.4025 - accuracy: 0.8510\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3929 - accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3836 - accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 12s 2ms/step - loss: 0.3779 - accuracy: 0.8601\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3753 - accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3693 - accuracy: 0.8631 \n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3679 - accuracy: 0.8626\n",
      "Score for fold 21: loss of 1.1557475328445435; accuracy of 44.69696879386902%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 22 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5836 - accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.4435 - accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4136 - accuracy: 0.8472\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3975 - accuracy: 0.8528\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3854 - accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3793 - accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3704 - accuracy: 0.8638\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3678 - accuracy: 0.8644\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3603 - accuracy: 0.8665\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3601 - accuracy: 0.8668\n",
      "Score for fold 22: loss of 0.9857214093208313; accuracy of 75.11363625526428%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 23 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.5737 - accuracy: 0.7784: 0s - los - ETA: 0s - loss: 0.5786  - ETA: 0s - loss: 0.5745 - accuracy: \n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4417 - accuracy: 0.8382\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4110 - accuracy: 0.8490\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3962 - accuracy: 0.8526\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3857 - accuracy: 0.8568\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 992us/step - loss: 0.3808 - accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 6s 904us/step - loss: 0.3762 - accuracy: 0.8603\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 947us/step - loss: 0.3697 - accuracy: 0.86250s - loss: 0.3695 - ac\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3681 - accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3646 - accuracy: 0.8644\n",
      "Score for fold 23: loss of 1.5085980892181396; accuracy of 70.58712244033813%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 24 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5888 - accuracy: 0.7694\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4482 - accuracy: 0.8318\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.4208 - accuracy: 0.8429\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.4034 - accuracy: 0.8497\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3924 - accuracy: 0.8542\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3832 - accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3780 - accuracy: 0.8592\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3717 - accuracy: 0.8617\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3673 - accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8641\n",
      "Score for fold 24: loss of 1.0154330730438232; accuracy of 60.700756311416626%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 25 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5863 - accuracy: 0.7704\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4482 - accuracy: 0.8323\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4175 - accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4002 - accuracy: 0.8506\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3905 - accuracy: 0.8526\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3827 - accuracy: 0.8576\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3795 - accuracy: 0.8577\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3728 - accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3688 - accuracy: 0.8619\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3673 - accuracy: 0.8620\n",
      "Score for fold 25: loss of 0.43865084648132324; accuracy of 88.04924488067627%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 26 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5745 - accuracy: 0.7770\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4410 - accuracy: 0.8377\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4117 - accuracy: 0.8482\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3954 - accuracy: 0.8536\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3842 - accuracy: 0.8584\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3811 - accuracy: 0.8593\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3753 - accuracy: 0.8624\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3721 - accuracy: 0.8619\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3694 - accuracy: 0.8643\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3655 - accuracy: 0.8654\n",
      "Score for fold 26: loss of 3.6184940338134766; accuracy of 9.791667014360428%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 27 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5809 - accuracy: 0.7766\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4430 - accuracy: 0.8383\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4119 - accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3963 - accuracy: 0.8539\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3833 - accuracy: 0.8602\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3784 - accuracy: 0.8611\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3730 - accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3680 - accuracy: 0.8644\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3668 - accuracy: 0.8651\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3630 - accuracy: 0.8652\n",
      "Score for fold 27: loss of 1.025904655456543; accuracy of 57.84090757369995%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 28 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5758 - accuracy: 0.7800\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4355 - accuracy: 0.8419\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4017 - accuracy: 0.8529\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3879 - accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3789 - accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3725 - accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3686 - accuracy: 0.8653\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3639 - accuracy: 0.8665\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3612 - accuracy: 0.8669\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3587 - accuracy: 0.8683\n",
      "Score for fold 28: loss of 3.1578853130340576; accuracy of 24.223485589027405%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 29 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5915 - accuracy: 0.7707\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4462 - accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4129 - accuracy: 0.8488\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3951 - accuracy: 0.8552\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3882 - accuracy: 0.8577\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 28s 4ms/step - loss: 0.3805 - accuracy: 0.8601\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3725 - accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3708 - accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3689 - accuracy: 0.8645\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3643 - accuracy: 0.8658\n",
      "Score for fold 29: loss of 0.8024626970291138; accuracy of 86.93181872367859%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 30 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5852 - accuracy: 0.7734\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4475 - accuracy: 0.8345\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4147 - accuracy: 0.8479\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3968 - accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3846 - accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3745 - accuracy: 0.8611\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3684 - accuracy: 0.8635\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3645 - accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3625 - accuracy: 0.8657\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3585 - accuracy: 0.8666\n",
      "Score for fold 30: loss of 1.0523985624313354; accuracy of 64.67803120613098%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 31 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5822 - accuracy: 0.7730\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4458 - accuracy: 0.8363\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4144 - accuracy: 0.8496\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3985 - accuracy: 0.8553\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3872 - accuracy: 0.8593\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3830 - accuracy: 0.8602\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3790 - accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3744 - accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3723 - accuracy: 0.8652: 0s - loss:\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3654 - accuracy: 0.8670\n",
      "Score for fold 31: loss of 1.0543161630630493; accuracy of 59.109848737716675%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 32 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.5763 - accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.4407 - accuracy: 0.8380\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4120 - accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3941 - accuracy: 0.8535: 0s - loss: 0.3943 - accura\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3846 - accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3759 - accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3721 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3681 - accuracy: 0.8626\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3646 - accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3610 - accuracy: 0.8663\n",
      "Score for fold 32: loss of 1.4833511114120483; accuracy of 46.0037887096405%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 33 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.5891 - accuracy: 0.7723\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4502 - accuracy: 0.8340\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4185 - accuracy: 0.8467\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4007 - accuracy: 0.8539\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3917 - accuracy: 0.8562\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3838 - accuracy: 0.8593\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3787 - accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3727 - accuracy: 0.8631\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3674 - accuracy: 0.8651\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3646 - accuracy: 0.8660\n",
      "Score for fold 33: loss of 0.558984637260437; accuracy of 76.04166865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 34 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5832 - accuracy: 0.7746\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4429 - accuracy: 0.8361\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4139 - accuracy: 0.8466\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3974 - accuracy: 0.8527\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3877 - accuracy: 0.8553\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3816 - accuracy: 0.8578\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3739 - accuracy: 0.8608\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3711 - accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8653\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3620 - accuracy: 0.8654\n",
      "Score for fold 34: loss of 0.6881036758422852; accuracy of 81.4393937587738%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 35 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5769 - accuracy: 0.7766\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4442 - accuracy: 0.8368\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4156 - accuracy: 0.8475\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4013 - accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3918 - accuracy: 0.8557\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3845 - accuracy: 0.8588: 0s - l\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3793 - accuracy: 0.8603\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3726 - accuracy: 0.8623\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3698 - accuracy: 0.8628\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3652 - accuracy: 0.8640\n",
      "Score for fold 35: loss of 0.9733559489250183; accuracy of 81.79924488067627%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 36 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5834 - accuracy: 0.7763\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.4514 - accuracy: 0.8345\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4224 - accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4081 - accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3973 - accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 7s 935us/step - loss: 0.3884 - accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 7s 983us/step - loss: 0.3829 - accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 7s 927us/step - loss: 0.3780 - accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3740 - accuracy: 0.8634: \n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 7s 1ms/step - loss: 0.3707 - accuracy: 0.8641\n",
      "Score for fold 36: loss of 0.5236114263534546; accuracy of 75.6818175315857%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 37 ...\n",
      "Epoch 1/10\n",
      "7095/7095 [==============================] - 8s 1ms/step - loss: 0.5816 - accuracy: 0.7734\n",
      "Epoch 2/10\n",
      "7095/7095 [==============================] - 8s 1ms/step - loss: 0.4417 - accuracy: 0.8371: 0s - loss: 0.4422 - accuracy\n",
      "Epoch 3/10\n",
      "7095/7095 [==============================] - 14s 2ms/step - loss: 0.4121 - accuracy: 0.8478\n",
      "Epoch 4/10\n",
      "7095/7095 [==============================] - 8s 1ms/step - loss: 0.3974 - accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "7095/7095 [==============================] - 6s 908us/step - loss: 0.3864 - accuracy: 0.8567\n",
      "Epoch 6/10\n",
      "7095/7095 [==============================] - 6s 854us/step - loss: 0.3802 - accuracy: 0.8591\n",
      "Epoch 7/10\n",
      "7095/7095 [==============================] - 6s 849us/step - loss: 0.3738 - accuracy: 0.8617\n",
      "Epoch 8/10\n",
      "7095/7095 [==============================] - 6s 849us/step - loss: 0.3684 - accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "7095/7095 [==============================] - 7s 940us/step - loss: 0.3660 - accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "7095/7095 [==============================] - 7s 1ms/step - loss: 0.3615 - accuracy: 0.8667\n",
      "Score for fold 37: loss of 0.5552641749382019; accuracy of 78.33333611488342%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 38 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.5814 - accuracy: 0.7770\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.4467 - accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.4182 - accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 21s 3ms/step - loss: 0.4052 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3955 - accuracy: 0.8558\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3917 - accuracy: 0.8559\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3841 - accuracy: 0.8589\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3791 - accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3736 - accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3709 - accuracy: 0.8638: 0s - loss: 0.3\n",
      "Score for fold 38: loss of 0.3869461417198181; accuracy of 87.3674213886261%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 39 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5746 - accuracy: 0.7783\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.4383 - accuracy: 0.8369\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 15s 2ms/step - loss: 0.4100 - accuracy: 0.8479\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3953 - accuracy: 0.8540: 0s - loss: 0.3956 \n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3861 - accuracy: 0.8569\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.3776 - accuracy: 0.8588\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3742 - accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3692 - accuracy: 0.8621\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3643 - accuracy: 0.8639\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3631 - accuracy: 0.8648\n",
      "Score for fold 39: loss of 1.488463282585144; accuracy of 58.71211886405945%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 40 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.5751 - accuracy: 0.7800\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4339 - accuracy: 0.8414\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.4041 - accuracy: 0.8521\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3891 - accuracy: 0.8566 0s - loss: 0.3897 - \n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 22s 3ms/step - loss: 0.3799 - accuracy: 0.8601\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 20s 3ms/step - loss: 0.3721 - accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3660 - accuracy: 0.8657\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3637 - accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3590 - accuracy: 0.8695\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.3565 - accuracy: 0.8708\n",
      "Score for fold 40: loss of 1.898891806602478; accuracy of 29.943183064460754%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 41 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 9s 1ms/step - loss: 0.5869 - accuracy: 0.7738\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 15s 2ms/step - loss: 0.4403 - accuracy: 0.8369 0s - loss: 0\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.4102 - accuracy: 0.8479\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3928 - accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 17s 2ms/step - loss: 0.3842 - accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 17s 2ms/step - loss: 0.3764 - accuracy: 0.8606 2s - loss: 0.3762 - accuracy: 0.\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 17s 2ms/step - loss: 0.3693 - accuracy: 0.8638\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 19s 3ms/step - loss: 0.3668 - accuracy: 0.8643\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3635 - accuracy: 0.8655\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3586 - accuracy: 0.8679\n",
      "Score for fold 41: loss of 0.5096838474273682; accuracy of 79.867422580719%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 42 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 15s 2ms/step - loss: 0.5719 - accuracy: 0.7800 1s - l\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.4383 - accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 17s 2ms/step - loss: 0.4096 - accuracy: 0.8511\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 19s 3ms/step - loss: 0.3934 - accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 20s 3ms/step - loss: 0.3837 - accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 18s 3ms/step - loss: 0.3761 - accuracy: 0.8629\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 20s 3ms/step - loss: 0.3697 - accuracy: 0.8646\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3673 - accuracy: 0.8661\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 15s 2ms/step - loss: 0.3623 - accuracy: 0.8677\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3581 - accuracy: 0.8689\n",
      "Score for fold 42: loss of 1.160006046295166; accuracy of 65.26514887809753%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 43 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.5778 - accuracy: 0.7773\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.4461 - accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.4163 - accuracy: 0.8474\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3985 - accuracy: 0.8537\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3899 - accuracy: 0.8569\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3844 - accuracy: 0.8590\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 14s 2ms/step - loss: 0.3771 - accuracy: 0.8621\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3726 - accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 20s 3ms/step - loss: 0.3702 - accuracy: 0.8648\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 16s 2ms/step - loss: 0.3670 - accuracy: 0.8660\n",
      "Score for fold 43: loss of 0.5261902213096619; accuracy of 73.10606241226196%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 44 ...\n",
      "Epoch 1/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.5772 - accuracy: 0.7771\n",
      "Epoch 2/10\n",
      "7013/7013 [==============================] - 8s 1ms/step - loss: 0.4406 - accuracy: 0.8384\n",
      "Epoch 3/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.4105 - accuracy: 0.8491\n",
      "Epoch 4/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3961 - accuracy: 0.8547\n",
      "Epoch 5/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3859 - accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "7013/7013 [==============================] - 13s 2ms/step - loss: 0.3800 - accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "7013/7013 [==============================] - 11s 2ms/step - loss: 0.3768 - accuracy: 0.8615 0s - loss:\n",
      "Epoch 8/10\n",
      "7013/7013 [==============================] - 28s 4ms/step - loss: 0.3719 - accuracy: 0.8630\n",
      "Epoch 9/10\n",
      "7013/7013 [==============================] - 10s 1ms/step - loss: 0.3695 - accuracy: 0.8639\n",
      "Epoch 10/10\n",
      "7013/7013 [==============================] - 27s 4ms/step - loss: 0.3657 - accuracy: 0.8653\n",
      "Score for fold 44: loss of 0.9392616748809814; accuracy of 57.026517391204834%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 45 ...\n",
      "Epoch 1/10\n",
      "7095/7095 [==============================] - 25s 3ms/step - loss: 0.5819 - accuracy: 0.7749\n",
      "Epoch 2/10\n",
      "7095/7095 [==============================] - 10s 1ms/step - loss: 0.4478 - accuracy: 0.8357\n",
      "Epoch 3/10\n",
      "7095/7095 [==============================] - 11s 2ms/step - loss: 0.4158 - accuracy: 0.8477\n",
      "Epoch 4/10\n",
      "7095/7095 [==============================] - 7s 1ms/step - loss: 0.3992 - accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "7095/7095 [==============================] - 8s 1ms/step - loss: 0.3894 - accuracy: 0.8570: \n",
      "Epoch 6/10\n",
      "7095/7095 [==============================] - 10s 1ms/step - loss: 0.3815 - accuracy: 0.8596\n",
      "Epoch 7/10\n",
      "7095/7095 [==============================] - 33s 5ms/step - loss: 0.3728 - accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "7095/7095 [==============================] - 15s 2ms/step - loss: 0.3695 - accuracy: 0.8638\n",
      "Epoch 9/10\n",
      "7095/7095 [==============================] - 15s 2ms/step - loss: 0.3643 - accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "7095/7095 [==============================] - 17s 2ms/step - loss: 0.3586 - accuracy: 0.8678\n",
      "Score for fold 45: loss of 1.048076868057251; accuracy of 68.82575750350952%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.8199766874313354 - Accuracy: 68.21969747543335%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 3.07902455329895 - Accuracy: 41.912877559661865%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.0879307985305786 - Accuracy: 69.26136612892151%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 1.278082251548767 - Accuracy: 55.71969747543335%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 1.2896097898483276 - Accuracy: 55.75757622718811%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 1.4960379600524902 - Accuracy: 55.30303120613098%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.5899096131324768 - Accuracy: 74.73484873771667%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 1.363754153251648 - Accuracy: 50.43560862541199%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 0.6297767162322998 - Accuracy: 82.15909004211426%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 5.357129096984863 - Accuracy: 19.33712065219879%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 11 - Loss: 8.96064567565918 - Accuracy: 13.428030908107758%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 12 - Loss: 1.4444950819015503 - Accuracy: 61.6287887096405%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 13 - Loss: 1.038083791732788 - Accuracy: 70.37878632545471%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 14 - Loss: 1.5127209424972534 - Accuracy: 47.121211886405945%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 15 - Loss: 0.6717286109924316 - Accuracy: 67.91666746139526%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 16 - Loss: 5.605130195617676 - Accuracy: 18.106061220169067%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 17 - Loss: 0.4586189389228821 - Accuracy: 64.05302882194519%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 18 - Loss: 1.9721722602844238 - Accuracy: 27.007576823234558%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 19 - Loss: 0.6462146639823914 - Accuracy: 80.07575869560242%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 20 - Loss: 0.8612075448036194 - Accuracy: 70.01894116401672%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 21 - Loss: 1.1557475328445435 - Accuracy: 44.69696879386902%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 22 - Loss: 0.9857214093208313 - Accuracy: 75.11363625526428%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 23 - Loss: 1.5085980892181396 - Accuracy: 70.58712244033813%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 24 - Loss: 1.0154330730438232 - Accuracy: 60.700756311416626%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 25 - Loss: 0.43865084648132324 - Accuracy: 88.04924488067627%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 26 - Loss: 3.6184940338134766 - Accuracy: 9.791667014360428%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 27 - Loss: 1.025904655456543 - Accuracy: 57.84090757369995%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 28 - Loss: 3.1578853130340576 - Accuracy: 24.223485589027405%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 29 - Loss: 0.8024626970291138 - Accuracy: 86.93181872367859%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 30 - Loss: 1.0523985624313354 - Accuracy: 64.67803120613098%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 31 - Loss: 1.0543161630630493 - Accuracy: 59.109848737716675%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 32 - Loss: 1.4833511114120483 - Accuracy: 46.0037887096405%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 33 - Loss: 0.558984637260437 - Accuracy: 76.04166865348816%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 34 - Loss: 0.6881036758422852 - Accuracy: 81.4393937587738%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 35 - Loss: 0.9733559489250183 - Accuracy: 81.79924488067627%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 36 - Loss: 0.5236114263534546 - Accuracy: 75.6818175315857%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 37 - Loss: 0.5552641749382019 - Accuracy: 78.33333611488342%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 38 - Loss: 0.3869461417198181 - Accuracy: 87.3674213886261%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 39 - Loss: 1.488463282585144 - Accuracy: 58.71211886405945%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 40 - Loss: 1.898891806602478 - Accuracy: 29.943183064460754%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 41 - Loss: 0.5096838474273682 - Accuracy: 79.867422580719%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 42 - Loss: 1.160006046295166 - Accuracy: 65.26514887809753%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 43 - Loss: 0.5261902213096619 - Accuracy: 73.10606241226196%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 44 - Loss: 0.9392616748809814 - Accuracy: 57.026517391204834%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 45 - Loss: 1.048076868057251 - Accuracy: 68.82575750350952%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 59.860269675652184 (+- 20.59283255534238)\n",
      "> Loss: 1.5270678348011442\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Lists to store metrics\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "groups = X_train_df['Subject_ID'].values \n",
    "inputs = X_train\n",
    "targets = y_train_dummy\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "logo.get_n_splits(inputs, targets, groups)\n",
    "\n",
    "cv = logo.split(inputs, targets, groups)\n",
    "\n",
    "# LOGO\n",
    "fold_no = 1\n",
    "for train, test in cv:\n",
    "    #Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax')) #4 outputs are possible \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "      # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568/1568 [==============================] - 1s 841us/step - loss: 1.9498 - accuracy: 0.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9498156309127808, 0.5696371793746948]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** is generated to observe where the model is classifying well and to see classes which the model is not classifying well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14605,  6028,  1511,   656],\n",
       "       [ 1794, 10617,  3753,  2076],\n",
       "       [  646,  1233,  2435,   246],\n",
       "       [  427,  3117,   100,   916]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **accuracy** score represents the proportion of correct classifications over all classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5696371610845296"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **F1 score** is a composite metric of two other metrics:\n",
    "\n",
    "Specificity: proportion of correct 'positive predictions' over all 'positive' predictions.\n",
    "\n",
    "Sensitivity: number of correct 'negative' predictions over all 'negative' predictions.\n",
    "\n",
    "The F1 score gives insight as to whether all classes are predicted correctly at the same rate. A low F1 score and high accuracy can indicate that only a majority class is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5820125460946117"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
